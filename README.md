# Paper-List-for-DL-and-CV-Beginners
In this repository, we share a curated collection of papers to help beginners get started with deep learning and computer vision

## Graph Neural Network

Semi-supervised classification with graph convolutional networks. ICLR17

Graph attention networks. Arxiv17

## Pose Estimation

FRAME: Floor-aligned Representation for Avatar Motion from Egocentric Video. CVPR25

3D human pose estimation with spatial and temporal transformers. ICCV21

## Multimodal

Learning Transferable Visual Models From Natural Language Supervision. ICML21

## Visual Localization

From Coarse to Fine: Robust Hierarchical Localization at Large Scale. CVPR19

Map-Relative Pose Regression for Visual Re-Localization. CVPR24

Map-free Visual Relocalization: Metric Pose Relative to a Single Image. ECCV22

A Survey on Monocular Re-Localization: From the Perspective of Scene Map Representation. TIV24

Long-term Visual Localization with Mobile Sensors. CVPR23

## Panoramic Visual Localization

LDL: Line Distance Functions for Panoramic Localization. ICCV23

PICCOLO: Point Cloud-Centric Omnidirectional Localization. ICCV21

Fully Geometric Panoramic Localization. CVPR24

## Visual Place Recognition

BoQ: A Place is Worth a Bag of Learnable Queries. CVPR24 

Deep Homography Estimation for Visual Place Recognition. AAAI24 

CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition. CVPR24 

EDTformer: An Efficient Decoder Transformer for Visual Place Recognition. TCSVT25

TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place Recognition. RAL25

SuperVLAD: Compact and Robust Image Descriptors for Visual Place Recognition. Neurips24

Optimal Transport Aggregation for Visual Place Recognition. CVPR24

Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition. ICLR24

MixVPR: Feature Mixing for Visual Place Recognition. WACV23

Focus on Local: Finding Reliable Discriminative Regions for Visual Place Recognition. AAAI25

EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition. ICCV23

Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era. Neurips25

MeshVPR: Citywide Visual Place Recognition Using 3D Meshes. ECCV24

Rethinking Visual Geo-localization for Large-Scale Applications. CVPR22

AnyLoc: Towards Universal Visual Place Recognition. ICRA24
 
## General Visual Tasks

OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels. CVPR25

An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR21

LeViT: a Vision Transformer in ConvNetâ€™s Clothing for Faster Inference. ICCV21

Is Space-Time Attention All You Need for Video Understanding? ICML21

Masked Autoencoders Are Scalable Vision Learners. CVPR22

Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. ICCV21.

Not all patches are what you need: Expediting vision transformers via token reorganization. ICLR22

Vision Transformer with Deformable Attention. CVPR22

Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model.ICML24

MambaOut: Do We Really Need Mamba for Vision? CVPR25

Vision Transformers Need Registers. ICLR24

Segment Anything. ICCV23

Deep residual learning for image recognition. CVPR16

## Local Feature Macth

SFD2: Semantic-guided Feature Detection and Description. CVPR23

DKM: Dense Kernelized Feature Matching for Geometry Estimation. CVPR23

RoMa: Robust Dense Feature Matching. CVPR24.

Efficient LoFTR: Semi-Dense Local Feature Matching with Sparse-Like Speed. CVPR24

EDM: Efficient Deep Feature Matching. ICCV25

CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral Subpixel-Level Semi-Dense Image Matching. ICCV25

JamMa: Ultra-lightweight Local Feature Matching with Joint Mamba. CVPR25

LoFTR: Detector-Free Local Feature Matching with Transformers. CVPR21

SuperGlue: Learning Feature Matching with Graph Neural Networks. CVPR20

## Interpretability

Grad-cam: Visual explanations from deep networks via gradient-based localization. ICCV17

## Visual Foundation Models

VGGT: Visual Geometry Grounded Transformer. CVPR25

DINOv2: Learning Robust Visual Features without Supervision. TMLR24

DINOv3. Arxiv25

## Face Recognition

FaceNet: A Unified Embedding for Face Recognition and Clustering. CVPR15

ArcFace: Additive Angular Margin Loss for Deep Face Recognition. CVPR19

## Diffusion 
Do Text-free Diffusion Models Learn Discriminative Visual Representations? ECCV24

Diffusion Models and Representation Learning: A Survey. TPAMI23

## Knowledge Distillation

Improving Language Model Distillation through Hidden State Matching. ICLR25

Rethinking Centered Kernel Alignment in Knowledge Distillation. IJCAI24

Single teacher, multiple perspectives: Teacher knowledge augmentation for enhanced knowledge distillation. ICLR25

## LLM

Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free. Neurips25

## Others

Attention Is All You Need. Neurips17

Mamba: Linear-Time Sequence Modeling with Selective State Spaces. COLM24.


