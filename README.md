# Paper-List-for-DL-and-CV-Beginners
In this repository, we share a curated collection of papers to help beginners get started with deep learning and computer vision
## Visual Place Recognition
BoQ: A Place is Worth a Bag of Learnable Queries. CVPR24 

Deep Homography Estimation for Visual Place Recognition. AAAI24 

CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition. CVPR24 

EDTformer: An Efficient Decoder Transformer for Visual Place Recognition. TCSVT25

TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place Recognition. RAL25

SuperVLAD: Compact and Robust Image Descriptors for Visual Place Recognition. Neurips24

Optimal Transport Aggregation for Visual Place Recognition. CVPR24

Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition. ICLR24

MixVPR: Feature Mixing for Visual Place Recognition. WACV23

Focus on Local: Finding Reliable Discriminative Regions for Visual Place Recognition. AAAI25

EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition. ICCV23

Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era. Neurips25

MeshVPR: Citywide Visual Place Recognition Using 3D Meshes. ECCV24

Rethinking Visual Geo-localization for Large-Scale Applications. CVPR22

AnyLoc: Towards Universal Visual Place Recognition. ICRA24
 
## General Visual Tasks

OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels. CVPR25

An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR21

LeViT: a Vision Transformer in ConvNetâ€™s Clothing for Faster Inference. ICCV21

Is Space-Time Attention All You Need for Video Understanding? ICML21

Masked Autoencoders Are Scalable Vision Learners. CVPR22

Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. ICCV21.

Not all patches are what you need: Expediting vision transformers via token reorganization. ICLR22

Vision Transformer with Deformable Attention. CVPR22

Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model.ICML24

MambaOut: Do We Really Need Mamba for Vision? CVPR25

## Diffusion 
Do Text-free Diffusion Models Learn Discriminative Visual Representations? ECCV24

Diffusion Models and Representation Learning: A Survey. TPAMI23

## Others

Attention Is All You Need. Neurips17

Mamba: Linear-Time Sequence Modeling with Selective State Spaces. COLM24.
